<script>
	window.onmessage = async (event) => {
		if (event.data.pluginMessage.type === 'cancel') {
			window.activeRequest.abort()
		}

		if (event.data.pluginMessage.type === 'submit-stream') {
			const {messages, key, model, temp, topP} = event.data.pluginMessage
			const isGPT = () => model.startsWith('gpt')
			const xhr = new XMLHttpRequest()

			// Set up the request
			xhr.open(
				'POST',
				isGPT()
					? 'https://api.openai.com/v1/chat/completions'
					: 'https://api.anthropic.com/v1/complete',
				true
			)
			xhr.setRequestHeader('Content-Type', 'application/json')
			isGPT()
				? xhr.setRequestHeader('Authorization', `Bearer ${key}`)
				: xhr.setRequestHeader('x-API-Key', key)

			// Handle errors
			xhr.onload = () => {
				try {
					// try to parse the response
					// (if we can parse it, it is an error)
					const response = JSON.parse(xhr.response)
					if (response.error) {
						// ERROR
						debugger
						window.parent.postMessage(
							{pluginMessage: {error: response.error}},
							'*'
						)
						return
					}
				} catch (e) {
					// Unparseable response
					// It is likely a stream response
					// (this is a good thing, it means its not an error)
				}
			}

			// Handle streaming
			xhr.onreadystatechange = function () {
				const {responseText, readyState, status} = xhr
				console.log('READY STATE CHANGE', {
					responseText,
					readyState,
					status
				})
				const messagesWithoutSystem = messages.filter(
					(msg) => msg.role !== 'system'
				)
				if (xhr.readyState === 4 && xhr.status === 0) {
					// CORS error
					window.parent.postMessage(
						{
							pluginMessage: {
								error: {
									message:
										'No Proxy URL set.\nFigChat cannot call Claude directly due to CORS.\nSet a Proxy URL and try again.'
								}
							}
						},
						'*'
					)
					return
				}
				if (xhr.readyState === 3 && xhr.status === 200) {
					console.log('STREAMING')
					// STREAMING
					const completion = extractAndCombineData(xhr.responseText)
					console.log(completion)
					window.parent.postMessage(
						{
							pluginMessage: {
								messages: [
									...messagesWithoutSystem,
									completion
								],
								state: 'streaming'
							}
						},
						'*'
					)
				}
				if (xhr.readyState === 4 && xhr.status === 200) {
					// COMPLETE
					window.activeRequest = undefined
					const completion = extractAndCombineData(xhr.responseText)
					console.log(completion)
					window.parent.postMessage(
						{
							pluginMessage: {
								messages: [
									...messagesWithoutSystem.filter(
										(msg) => msg.role !== 'system'
									),
									completion
								],
								state: 'complete'
							}
						},
						'*'
					)
				}
			}
			xhr.send(
				JSON.stringify({
					model,
					messages: messages.map((msg) => {
						// Remove the "collapsed" property before sending to OpenAI
						const {collapsed, ...rest} = msg
						return rest
					}),
					temperature: temp,
					top_p: topP,
					stream: true
				})
			)
		}
	}

	function extractAndCombineData(responseText) {
		const lines = responseText.split('\n')
		let combinedDelta = {role: '', content: ''}

		for (const line of lines) {
			if (line.startsWith('data:')) {
				const jsonString = line.substring(5).trim() // Remove the "data:" prefix

				try {
					const jsonObj = JSON.parse(jsonString)

					if (
						jsonObj.choices &&
						jsonObj.choices[0] &&
						jsonObj.choices[0].delta
					) {
						const delta = jsonObj.choices[0].delta

						if (delta.role) {
							combinedDelta.role = delta.role
						}

						if (delta.content) {
							combinedDelta.content += delta.content
						}
					}
				} catch (error) {
					// Ignore any parsing errors, such as "data: [DONE]" message
				}
			}
		}

		return combinedDelta
	}
</script>
